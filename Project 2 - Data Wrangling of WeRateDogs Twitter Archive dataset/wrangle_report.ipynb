{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wrangle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is part of Data wrangling section of Udacity Data Analyst Nanodegree. It involves using Python and its libraries, gathing data from a variety of sources and in variety of formats, assess its quality and tidiness then clean, document all the wrangling efforts in a Jupyter Notebook and finally showcase them through analyses and visualization using Python\n",
    "\n",
    "The project tasks are structured as follows:\n",
    "1. Gathering data\n",
    "2. Assessing data\n",
    "3. Cleaning data\n",
    "4. Storing data\n",
    "5. Analyzing & visualizing the data\n",
    "6. Reporting: - data wrangling efforts in this document & data analyses and visualizations in act_report\n",
    "\n",
    "### Gathering data:\n",
    "I gathered all the three different formats pieces of data from different sources using different methods as follows:\n",
    "* Twitter archive data.\n",
    "I gathered the `twitter_archive_enhanced.csv` by downloading the file manually from Udacity, upload it and read it into pandas DataFrame.\n",
    "* The tweet image predictions.\n",
    "Gathered the `image_predictions.tsv` by downloading it programmatically from Udacity's servers using the Request library and the URL containing the file.\n",
    "* Additional data from the Twitter API.\n",
    "Gathered each tweet's retweet count and favorite count by creating an API object to use to gather twitter data, then queried each tweet ID, wrote its JSON data to a `tweet_json.txt` file with each tweet's JSON data on its own line and lastly read the file line by line and created a pandas DataFrame from the list of dictionaries.\n",
    "\n",
    "### Assessing the data:\n",
    "After gathering the three pieces of data, I assessed them both visually and programmatically where I detected both tidiness (structural) and quality (content) issues.\n",
    "\n",
    "In visual assessment, for example; I detected a tidiness issue where doggo, floofer, pupper and puppo which are dog_stages in separate columns instead a single column from the twitter archive data and a quality issue where some breed of dog predictions were false.\n",
    "\n",
    "In programmatic assessment I identified most quality and tidiness issues. For instance, some dog names were in lowercase.\n",
    "\n",
    "After the assessments, I documented all issues I detected into two groups quality and tidiness issues.\n",
    "\n",
    "### Cleaning the data:\n",
    "In this section, I firstly created copies of the three original dataframes. I then proceeded to cleaning both the tidiness and quality issues I detected and documented from assessing the data section in three steps define, code and test.\n",
    "\n",
    "I started cleaning tidiness issues where i merged the three dataframes into one dataframe and cleaned some quality issues alongside related to some tidiness issues. I changed dataypes for timestamp and tweet_id, re-extracted rating_numerator and rating_denominator from th text column and converted their datatypes, melted the four dog_stages into a single column and changed it's datatype, stripped the html urls from the source column and changed it's datatype and deleted unnecessary columns to name a few.\n",
    "\n",
    "### Storing the data:\n",
    "After cleaning the data, i stored the dataframe to CSV file `twitter_archive_master.csv`.\n",
    "\n",
    "\n",
    "              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
